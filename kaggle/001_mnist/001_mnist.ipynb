{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wget https://kaggle2.blob.core.windows.net/competitions-data/kaggle/3004/test.csv\n",
    "# wget https://kaggle2.blob.core.windows.net/competitions-data/kaggle/3004/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"train.csv\")\n",
    "csv_test = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(y):\n",
    "    return (np.arange(np.unique(y).__len__()) == y[:,None]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = csv.iloc[:,1:].values.astype(np.float32)\n",
    "X = np.multiply(X, 1.0 / 255.0)\n",
    "y = csv.iloc[:,0].values\n",
    "y_oh = to_one_hot(y)\n",
    "\n",
    "X_test = csv_test.iloc[:,:].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000,) (42000, 10) (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape, y_oh.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_height/image_width = 28/28\n"
     ]
    }
   ],
   "source": [
    "image_size = X.shape[1]\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "print(\"image_height/image_width = {}/{}\".format(image_width, image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#VALIDATION_SIZE = 2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wb(wshape=[None], bshape=[None], device='/cpu:0'):\n",
    "    with tf.device(device):\n",
    "        w = tf.get_variable(\"w\", wshape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b = tf.get_variable('b', bshape, initializer=tf.constant_initializer(0.0))\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    # W => (patch, patch, depth_from, depth_to)\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool1 (8, 14, 14, 32)\n",
      "pool2 (8, 7, 7, 64)\n",
      "pool1 (28000, 14, 14, 32)\n",
      "pool2 (28000, 7, 7, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "train_size = len(X)\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, 28, 28, 1))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, 10))\n",
    "  \n",
    "  # Variables.\n",
    "  with tf.variable_scope(\"convNetConvLayer1\"):\n",
    "        layer1_weights, layer1_biases = wb([3, 3, 1, 32], [32])\n",
    "  with tf.variable_scope(\"convNetConvLayer2\"):\n",
    "        layer2_weights, layer2_biases = wb([3, 3, 32, 32], [32])\n",
    "  with tf.variable_scope(\"convNetConvLayer3\"):\n",
    "        layer3_weights, layer3_biases = wb([3, 3, 32, 64], [64])\n",
    "  with tf.variable_scope(\"convNetConvLayer4\"):\n",
    "        layer4_weights, layer4_biases = wb([3, 3, 64, 64], [64])\n",
    "#   with tf.variable_scope(\"convNetConvLayer5\"):\n",
    "#         layer5_weights, layer5_biases = wb([3, 3, 64, 128], [128])\n",
    "#   with tf.variable_scope(\"convNetConvLayer6\"):\n",
    "#         layer6_weights, layer6_biases = wb([3, 3, 128, 128], [128])\n",
    "  with tf.variable_scope(\"convNetFC1\"):\n",
    "        layer_fc1_weights, layer_fc1_biases = wb([3136, 1024], [1024])\n",
    "  with tf.variable_scope(\"convNetFC2\"):\n",
    "        layer_fc2_weights, layer_fc2_biases = wb([1024, 10], [10])\n",
    "  \n",
    "  # Model with max_pool.\n",
    "  def model(data, train=True):\n",
    "    conv1 = tf.nn.relu(conv2d(data, layer1_weights) + layer1_biases)\n",
    "    conv2 = tf.nn.relu(conv2d(conv1, layer2_weights) + layer2_biases)\n",
    "    if train:\n",
    "        conv2 = tf.nn.dropout(conv2, 0.5)\n",
    "    pool1 = max_pool_2x2(conv2)\n",
    "    print(\"pool1\", pool1.get_shape())\n",
    "    \n",
    "    conv3 = tf.nn.relu(conv2d(pool1, layer3_weights) + layer3_biases)\n",
    "    conv4 = tf.nn.relu(conv2d(conv3, layer4_weights) + layer4_biases)\n",
    "    if train:\n",
    "        conv4 = tf.nn.dropout(conv4, 0.5)\n",
    "    pool2 = max_pool_2x2(conv4)\n",
    "    print(\"pool2\", pool2.get_shape())\n",
    "    \n",
    "#     conv5 = tf.nn.relu(conv2d(pool2, layer5_weights) + layer5_biases)\n",
    "#     conv6 = tf.nn.relu(conv2d(conv5, layer6_weights) + layer6_biases)\n",
    "#     if train:\n",
    "#         tf.nn.dropout(conv4, 0.5)\n",
    "#     pool3 = max_pool_2x2(conv6)\n",
    "#     print(\"pool3\", pool3.get_shape())\n",
    "    \n",
    "    shape = pool2.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    \n",
    "    fc1 = tf.nn.relu(tf.matmul(reshape, layer_fc1_weights) + layer_fc1_biases)\n",
    "    if train:\n",
    "        fc1 = tf.nn.dropout(fc1, 0.5)\n",
    "    fc2 = tf.matmul(fc1, layer_fc2_weights) + layer_fc2_biases\n",
    "    return fc2\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0, trainable=False)\n",
    "  learn_rate  = tf.train.exponential_decay(1e-4, global_step*batch_size, train_size, 0.5, staircase=True)\n",
    "  optimizer = tf.train.AdamOptimizer(learn_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  with tf.device(\"/cpu:0\"):  \n",
    "        tf_test_dataset = tf.constant(X_test)\n",
    "        test_prediction = tf.nn.softmax(model(tf.reshape(tf_test_dataset, (-1, 28, 28, 1)), train=False))\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52500\n",
      "step: 0, accuracy: 0.0, loss: 16.551673889160156, took 0.167\n",
      "step: 10, accuracy: 0.0, loss: 8.987409591674805, took 0.025\n",
      "step: 20, accuracy: 0.0, loss: 5.722247123718262, took 0.031\n",
      "step: 30, accuracy: 0.0, loss: 7.509032726287842, took 0.029\n",
      "step: 40, accuracy: 37.5, loss: 3.1486573219299316, took 0.031\n",
      "step: 50, accuracy: 0.0, loss: 4.42907190322876, took 0.024\n",
      "step: 60, accuracy: 25.0, loss: 5.88735294342041, took 0.024\n",
      "step: 70, accuracy: 0.0, loss: 5.055665016174316, took 0.024\n",
      "step: 80, accuracy: 0.0, loss: 4.0709662437438965, took 0.024\n",
      "step: 90, accuracy: 0.0, loss: 4.454544544219971, took 0.025\n",
      "step: 100, accuracy: 37.5, loss: 2.9129772186279297, took 0.024\n",
      "step: 200, accuracy: 37.5, loss: 2.075410842895508, took 0.021\n",
      "step: 300, accuracy: 25.0, loss: 2.3625922203063965, took 0.021\n",
      "step: 400, accuracy: 62.5, loss: 0.8393750786781311, took 0.021\n",
      "step: 500, accuracy: 75.0, loss: 1.0615410804748535, took 0.021\n",
      "step: 600, accuracy: 87.5, loss: 0.4297986626625061, took 0.021\n",
      "step: 700, accuracy: 62.5, loss: 0.8206052780151367, took 0.021\n",
      "step: 800, accuracy: 87.5, loss: 0.3109075725078583, took 0.021\n",
      "step: 900, accuracy: 75.0, loss: 0.4200458526611328, took 0.021\n",
      "step: 1000, accuracy: 87.5, loss: 0.32842904329299927, took 0.021\n",
      "step: 1100, accuracy: 87.5, loss: 0.286300390958786, took 0.021\n",
      "step: 1200, accuracy: 100.0, loss: 0.2258642613887787, took 0.021\n",
      "step: 1300, accuracy: 75.0, loss: 0.6008422374725342, took 0.021\n",
      "step: 1400, accuracy: 100.0, loss: 0.23126311600208282, took 0.021\n",
      "step: 1500, accuracy: 100.0, loss: 0.161391019821167, took 0.021\n",
      "step: 1600, accuracy: 62.5, loss: 0.8451757431030273, took 0.021\n",
      "step: 1700, accuracy: 100.0, loss: 0.20530609786510468, took 0.021\n",
      "step: 1800, accuracy: 87.5, loss: 0.21210117638111115, took 0.021\n",
      "step: 1900, accuracy: 100.0, loss: 0.04165729135274887, took 0.021\n",
      "step: 2000, accuracy: 100.0, loss: 0.07829621434211731, took 0.021\n",
      "step: 2100, accuracy: 100.0, loss: 0.08579519391059875, took 0.021\n",
      "step: 2200, accuracy: 100.0, loss: 0.039677731692790985, took 0.021\n",
      "step: 2300, accuracy: 100.0, loss: 0.06135907396674156, took 0.021\n",
      "step: 2400, accuracy: 100.0, loss: 0.09496720880270004, took 0.021\n",
      "step: 2500, accuracy: 87.5, loss: 0.17667421698570251, took 0.021\n",
      "step: 2600, accuracy: 87.5, loss: 0.6283378005027771, took 0.021\n",
      "step: 2700, accuracy: 75.0, loss: 0.929277777671814, took 0.021\n",
      "step: 2800, accuracy: 100.0, loss: 0.13798761367797852, took 0.023\n",
      "step: 2900, accuracy: 87.5, loss: 0.7397857308387756, took 0.021\n",
      "step: 3000, accuracy: 100.0, loss: 0.074351966381073, took 0.021\n",
      "step: 3100, accuracy: 100.0, loss: 0.013537652790546417, took 0.021\n",
      "step: 3200, accuracy: 100.0, loss: 0.05423980951309204, took 0.021\n",
      "step: 3300, accuracy: 100.0, loss: 0.0982944592833519, took 0.021\n",
      "step: 3400, accuracy: 100.0, loss: 0.02675427682697773, took 0.021\n",
      "step: 3500, accuracy: 87.5, loss: 0.9287581443786621, took 0.021\n",
      "step: 3600, accuracy: 100.0, loss: 0.006718670018017292, took 0.021\n",
      "step: 3700, accuracy: 100.0, loss: 0.023889249190688133, took 0.021\n",
      "step: 3800, accuracy: 100.0, loss: 0.05361999571323395, took 0.021\n",
      "step: 3900, accuracy: 87.5, loss: 0.36306032538414, took 0.021\n",
      "step: 4000, accuracy: 87.5, loss: 0.34420520067214966, took 0.021\n",
      "step: 4100, accuracy: 75.0, loss: 0.7281167507171631, took 0.021\n",
      "step: 4200, accuracy: 100.0, loss: 0.025922203436493874, took 0.021\n",
      "step: 4300, accuracy: 87.5, loss: 0.30260488390922546, took 0.022\n",
      "step: 4400, accuracy: 75.0, loss: 0.2406213879585266, took 0.021\n",
      "step: 4500, accuracy: 87.5, loss: 0.28432899713516235, took 0.021\n",
      "step: 4600, accuracy: 87.5, loss: 0.14229035377502441, took 0.021\n",
      "step: 4700, accuracy: 100.0, loss: 0.023712804540991783, took 0.021\n",
      "step: 4800, accuracy: 100.0, loss: 0.07802685350179672, took 0.021\n",
      "step: 4900, accuracy: 100.0, loss: 0.021374719217419624, took 0.021\n",
      "step: 5000, accuracy: 87.5, loss: 0.27518177032470703, took 0.021\n",
      "step: 5100, accuracy: 100.0, loss: 0.06558732688426971, took 0.021\n",
      "step: 5200, accuracy: 100.0, loss: 0.03645817190408707, took 0.021\n",
      "step: 5300, accuracy: 100.0, loss: 0.010923094116151333, took 0.021\n",
      "step: 5400, accuracy: 100.0, loss: 0.18837381899356842, took 0.021\n",
      "step: 5500, accuracy: 87.5, loss: 0.21378199756145477, took 0.021\n",
      "step: 5600, accuracy: 87.5, loss: 0.18286266922950745, took 0.021\n",
      "step: 5700, accuracy: 100.0, loss: 0.0021424239967018366, took 0.021\n",
      "step: 5800, accuracy: 100.0, loss: 0.009463583119213581, took 0.021\n",
      "step: 5900, accuracy: 100.0, loss: 0.07164861261844635, took 0.021\n",
      "step: 6000, accuracy: 100.0, loss: 0.05262758582830429, took 0.021\n",
      "step: 6100, accuracy: 100.0, loss: 0.005287286825478077, took 0.021\n",
      "step: 6200, accuracy: 87.5, loss: 1.0312834978103638, took 0.021\n",
      "step: 6300, accuracy: 87.5, loss: 0.4810834228992462, took 0.021\n",
      "step: 6400, accuracy: 100.0, loss: 0.0017007096903398633, took 0.021\n",
      "step: 6500, accuracy: 100.0, loss: 0.002839590422809124, took 0.021\n",
      "step: 6600, accuracy: 100.0, loss: 0.11658415198326111, took 0.021\n",
      "step: 6700, accuracy: 100.0, loss: 0.012637164443731308, took 0.021\n",
      "step: 6800, accuracy: 100.0, loss: 0.06882534921169281, took 0.021\n",
      "step: 6900, accuracy: 100.0, loss: 0.003976824693381786, took 0.021\n",
      "step: 7000, accuracy: 100.0, loss: 0.00303082587197423, took 0.021\n",
      "step: 7100, accuracy: 87.5, loss: 0.26503267884254456, took 0.021\n",
      "step: 7200, accuracy: 100.0, loss: 0.0002610491937957704, took 0.021\n",
      "step: 7300, accuracy: 100.0, loss: 0.018540840595960617, took 0.021\n",
      "step: 7400, accuracy: 100.0, loss: 0.004983291961252689, took 0.021\n",
      "step: 7500, accuracy: 100.0, loss: 0.008499247021973133, took 0.021\n",
      "step: 7600, accuracy: 100.0, loss: 0.007935818284749985, took 0.021\n",
      "step: 7700, accuracy: 75.0, loss: 0.20027127861976624, took 0.021\n",
      "step: 7800, accuracy: 100.0, loss: 0.003871816210448742, took 0.021\n",
      "step: 7900, accuracy: 87.5, loss: 0.18474695086479187, took 0.021\n",
      "step: 8000, accuracy: 100.0, loss: 0.004246798809617758, took 0.021\n",
      "step: 8100, accuracy: 100.0, loss: 0.04098853841423988, took 0.021\n",
      "step: 8200, accuracy: 100.0, loss: 0.03122648410499096, took 0.021\n",
      "step: 8300, accuracy: 100.0, loss: 0.013467307202517986, took 0.022\n",
      "step: 8400, accuracy: 87.5, loss: 0.2417599856853485, took 0.021\n",
      "step: 8500, accuracy: 100.0, loss: 0.016487978398799896, took 0.021\n",
      "step: 8600, accuracy: 100.0, loss: 0.09503447264432907, took 0.021\n",
      "step: 8700, accuracy: 100.0, loss: 0.007810249924659729, took 0.021\n",
      "step: 8800, accuracy: 100.0, loss: 0.04843847453594208, took 0.021\n",
      "step: 8900, accuracy: 87.5, loss: 0.12682966887950897, took 0.021\n",
      "step: 9000, accuracy: 87.5, loss: 0.16910652816295624, took 0.021\n",
      "step: 9100, accuracy: 100.0, loss: 0.10600802302360535, took 0.021\n",
      "step: 9200, accuracy: 87.5, loss: 0.3358174264431, took 0.021\n",
      "step: 9300, accuracy: 100.0, loss: 0.03703177347779274, took 0.021\n",
      "step: 9400, accuracy: 100.0, loss: 0.00582385016605258, took 0.021\n",
      "step: 9500, accuracy: 100.0, loss: 0.07837285101413727, took 0.021\n",
      "step: 9600, accuracy: 100.0, loss: 0.0017124749720096588, took 0.021\n",
      "step: 9700, accuracy: 100.0, loss: 0.025427546352148056, took 0.021\n",
      "step: 9800, accuracy: 87.5, loss: 0.44458407163619995, took 0.021\n",
      "step: 9900, accuracy: 100.0, loss: 0.0005946211749687791, took 0.021\n",
      "step: 10000, accuracy: 87.5, loss: 0.16132307052612305, took 0.021\n",
      "step: 10100, accuracy: 100.0, loss: 0.003569754771888256, took 0.021\n",
      "step: 10200, accuracy: 100.0, loss: 0.000447267375420779, took 0.021\n",
      "step: 10300, accuracy: 100.0, loss: 0.0014139970298856497, took 0.021\n",
      "step: 10400, accuracy: 87.5, loss: 0.4526142179965973, took 0.021\n",
      "step: 10500, accuracy: 100.0, loss: 0.0066979434341192245, took 0.021\n",
      "step: 10600, accuracy: 100.0, loss: 0.0015324269188567996, took 0.021\n",
      "step: 10700, accuracy: 100.0, loss: 0.012776460498571396, took 0.021\n",
      "step: 10800, accuracy: 100.0, loss: 0.009007476270198822, took 0.021\n",
      "step: 10900, accuracy: 87.5, loss: 0.4089031219482422, took 0.021\n",
      "step: 11000, accuracy: 100.0, loss: 0.018439551815390587, took 0.022\n",
      "step: 11100, accuracy: 100.0, loss: 0.0665208175778389, took 0.021\n",
      "step: 11200, accuracy: 100.0, loss: 0.012017227709293365, took 0.021\n",
      "step: 11300, accuracy: 100.0, loss: 0.021604377776384354, took 0.021\n",
      "step: 11400, accuracy: 100.0, loss: 0.006831790320575237, took 0.021\n",
      "step: 11500, accuracy: 100.0, loss: 0.0019345063483342528, took 0.021\n",
      "step: 11600, accuracy: 100.0, loss: 0.1141904890537262, took 0.021\n",
      "step: 11700, accuracy: 87.5, loss: 0.47480258345603943, took 0.021\n",
      "step: 11800, accuracy: 87.5, loss: 0.12503671646118164, took 0.021\n",
      "step: 11900, accuracy: 100.0, loss: 0.005612006410956383, took 0.021\n",
      "step: 12000, accuracy: 87.5, loss: 0.18396514654159546, took 0.021\n",
      "step: 12100, accuracy: 87.5, loss: 0.5341635942459106, took 0.021\n",
      "step: 12200, accuracy: 100.0, loss: 0.004526771139353514, took 0.021\n",
      "step: 12300, accuracy: 100.0, loss: 0.04214239865541458, took 0.021\n",
      "step: 12400, accuracy: 87.5, loss: 0.13124261796474457, took 0.021\n",
      "step: 12500, accuracy: 100.0, loss: 0.007242537569254637, took 0.021\n",
      "step: 12600, accuracy: 100.0, loss: 0.017495455220341682, took 0.021\n",
      "step: 12700, accuracy: 100.0, loss: 0.006279069930315018, took 0.021\n",
      "step: 12800, accuracy: 87.5, loss: 0.27404075860977173, took 0.021\n",
      "step: 12900, accuracy: 100.0, loss: 0.00363445607945323, took 0.021\n",
      "step: 13000, accuracy: 100.0, loss: 0.0170002244412899, took 0.021\n",
      "step: 13100, accuracy: 100.0, loss: 0.04408391937613487, took 0.021\n",
      "step: 13200, accuracy: 100.0, loss: 0.0577322393655777, took 0.021\n",
      "step: 13300, accuracy: 100.0, loss: 0.07257157564163208, took 0.021\n",
      "step: 13400, accuracy: 100.0, loss: 0.0009937784634530544, took 0.021\n",
      "step: 13500, accuracy: 87.5, loss: 0.2013949453830719, took 0.021\n",
      "step: 13600, accuracy: 100.0, loss: 0.030227893963456154, took 0.021\n",
      "step: 13700, accuracy: 87.5, loss: 0.11887878179550171, took 0.021\n",
      "step: 13800, accuracy: 75.0, loss: 0.3923424482345581, took 0.021\n",
      "step: 13900, accuracy: 100.0, loss: 0.12240580469369888, took 0.021\n",
      "step: 14000, accuracy: 100.0, loss: 0.0037100412882864475, took 0.021\n",
      "step: 14100, accuracy: 100.0, loss: 0.013554511591792107, took 0.021\n",
      "step: 14200, accuracy: 100.0, loss: 0.020960379391908646, took 0.021\n",
      "step: 14300, accuracy: 87.5, loss: 0.471319317817688, took 0.021\n",
      "step: 14400, accuracy: 100.0, loss: 0.0019230707548558712, took 0.021\n",
      "step: 14500, accuracy: 100.0, loss: 0.0009262833627872169, took 0.025\n",
      "step: 14600, accuracy: 100.0, loss: 0.005220925901085138, took 0.021\n",
      "step: 14700, accuracy: 100.0, loss: 0.08178465068340302, took 0.021\n",
      "step: 14800, accuracy: 100.0, loss: 0.00881012063473463, took 0.021\n",
      "step: 14900, accuracy: 100.0, loss: 0.017292212694883347, took 0.021\n",
      "step: 15000, accuracy: 87.5, loss: 0.5250749588012695, took 0.021\n",
      "step: 15100, accuracy: 100.0, loss: 0.014205779880285263, took 0.021\n",
      "step: 15200, accuracy: 100.0, loss: 0.003017724258825183, took 0.021\n",
      "step: 15300, accuracy: 100.0, loss: 8.408034045714885e-05, took 0.021\n",
      "step: 15400, accuracy: 87.5, loss: 0.423961877822876, took 0.021\n",
      "step: 15500, accuracy: 100.0, loss: 0.000159566814545542, took 0.021\n",
      "step: 15600, accuracy: 100.0, loss: 0.0636877790093422, took 0.021\n",
      "step: 15700, accuracy: 100.0, loss: 0.004901276435703039, took 0.021\n",
      "step: 15800, accuracy: 100.0, loss: 0.05411072447896004, took 0.021\n",
      "step: 15900, accuracy: 100.0, loss: 0.03534672409296036, took 0.021\n",
      "step: 16000, accuracy: 87.5, loss: 0.13224835693836212, took 0.021\n",
      "step: 16100, accuracy: 100.0, loss: 0.08554535359144211, took 0.021\n",
      "step: 16200, accuracy: 100.0, loss: 0.04239652678370476, took 0.021\n",
      "step: 16300, accuracy: 100.0, loss: 0.0076323035173118114, took 0.021\n",
      "step: 16400, accuracy: 100.0, loss: 0.0417424701154232, took 0.024\n",
      "step: 16500, accuracy: 100.0, loss: 0.0011289460817351937, took 0.021\n",
      "step: 16600, accuracy: 100.0, loss: 0.0006258719367906451, took 0.021\n",
      "step: 16700, accuracy: 100.0, loss: 0.020236996933817863, took 0.021\n",
      "step: 16800, accuracy: 100.0, loss: 0.014281952753663063, took 0.021\n",
      "step: 16900, accuracy: 87.5, loss: 0.42902684211730957, took 0.021\n",
      "step: 17000, accuracy: 100.0, loss: 0.020647572353482246, took 0.021\n",
      "step: 17100, accuracy: 100.0, loss: 0.0422169528901577, took 0.021\n",
      "step: 17200, accuracy: 100.0, loss: 0.00180936383549124, took 0.021\n",
      "step: 17300, accuracy: 100.0, loss: 0.024846568703651428, took 0.021\n",
      "step: 17400, accuracy: 75.0, loss: 0.6960772275924683, took 0.021\n",
      "step: 17500, accuracy: 87.5, loss: 0.2321380376815796, took 0.021\n",
      "step: 17600, accuracy: 100.0, loss: 0.01523534394800663, took 0.021\n",
      "step: 17700, accuracy: 100.0, loss: 0.061065297573804855, took 0.021\n",
      "step: 17800, accuracy: 100.0, loss: 0.04334914684295654, took 0.021\n",
      "step: 17900, accuracy: 100.0, loss: 0.059406060725450516, took 0.021\n",
      "step: 18000, accuracy: 100.0, loss: 0.0023115172516554594, took 0.021\n",
      "step: 18100, accuracy: 100.0, loss: 0.0002453162451274693, took 0.021\n",
      "step: 18200, accuracy: 100.0, loss: 0.0007091369479894638, took 0.021\n",
      "step: 18300, accuracy: 100.0, loss: 0.08838103711605072, took 0.021\n",
      "step: 18400, accuracy: 100.0, loss: 0.08640027046203613, took 0.021\n",
      "step: 18500, accuracy: 100.0, loss: 0.0011052301852032542, took 0.021\n",
      "step: 18600, accuracy: 100.0, loss: 0.013316947966814041, took 0.021\n",
      "step: 18700, accuracy: 100.0, loss: 0.006534256972372532, took 0.021\n",
      "step: 18800, accuracy: 100.0, loss: 0.056626107543706894, took 0.021\n",
      "step: 18900, accuracy: 87.5, loss: 0.12626968324184418, took 0.021\n",
      "step: 19000, accuracy: 100.0, loss: 0.0003955025167670101, took 0.021\n",
      "step: 19100, accuracy: 100.0, loss: 0.05416510999202728, took 0.021\n",
      "step: 19200, accuracy: 100.0, loss: 0.019527709111571312, took 0.021\n",
      "step: 19300, accuracy: 87.5, loss: 0.15958324074745178, took 0.021\n",
      "step: 19400, accuracy: 100.0, loss: 0.0032816946040838957, took 0.022\n",
      "step: 19500, accuracy: 100.0, loss: 0.0008336951141245663, took 0.021\n",
      "step: 19600, accuracy: 100.0, loss: 0.020441289991140366, took 0.021\n",
      "step: 19700, accuracy: 100.0, loss: 0.0007818604353815317, took 0.022\n",
      "step: 19800, accuracy: 100.0, loss: 0.0026683276519179344, took 0.021\n",
      "step: 19900, accuracy: 100.0, loss: 0.0022787118796259165, took 0.022\n",
      "step: 20000, accuracy: 100.0, loss: 0.0019738853443413973, took 0.021\n",
      "step: 20100, accuracy: 100.0, loss: 0.0009180745109915733, took 0.021\n",
      "step: 20200, accuracy: 100.0, loss: 0.0021676463074982166, took 0.022\n",
      "step: 20300, accuracy: 100.0, loss: 0.0007144882692955434, took 0.021\n",
      "step: 20400, accuracy: 100.0, loss: 0.012931600213050842, took 0.021\n",
      "step: 20500, accuracy: 100.0, loss: 0.021539079025387764, took 0.021\n",
      "step: 20600, accuracy: 87.5, loss: 0.39895424246788025, took 0.021\n",
      "step: 20700, accuracy: 100.0, loss: 0.08487896621227264, took 0.021\n",
      "step: 20800, accuracy: 87.5, loss: 0.17931406199932098, took 0.021\n",
      "step: 20900, accuracy: 100.0, loss: 0.08981809765100479, took 0.021\n",
      "step: 21000, accuracy: 100.0, loss: 0.008460060693323612, took 0.021\n",
      "step: 21100, accuracy: 100.0, loss: 0.008427086286246777, took 0.021\n",
      "step: 21200, accuracy: 100.0, loss: 0.012518965639173985, took 0.021\n",
      "step: 21300, accuracy: 100.0, loss: 0.004802279639989138, took 0.021\n",
      "step: 21400, accuracy: 87.5, loss: 0.3161081075668335, took 0.021\n",
      "step: 21500, accuracy: 100.0, loss: 0.004684797488152981, took 0.021\n",
      "step: 21600, accuracy: 100.0, loss: 0.0001261768484255299, took 0.021\n",
      "step: 21700, accuracy: 100.0, loss: 0.0003616735921241343, took 0.021\n",
      "step: 21800, accuracy: 100.0, loss: 0.004193875938653946, took 0.021\n",
      "step: 21900, accuracy: 100.0, loss: 0.055926576256752014, took 0.021\n",
      "step: 22000, accuracy: 100.0, loss: 0.0008675606222823262, took 0.021\n",
      "step: 22100, accuracy: 100.0, loss: 0.06911684572696686, took 0.021\n",
      "step: 22200, accuracy: 100.0, loss: 0.003711686935275793, took 0.021\n",
      "step: 22300, accuracy: 87.5, loss: 0.2076795995235443, took 0.023\n",
      "step: 22400, accuracy: 100.0, loss: 0.006690203677862883, took 0.021\n",
      "step: 22500, accuracy: 100.0, loss: 0.0012811915948987007, took 0.022\n",
      "step: 22600, accuracy: 100.0, loss: 0.02551868185400963, took 0.021\n",
      "step: 22700, accuracy: 100.0, loss: 0.038433998823165894, took 0.021\n",
      "step: 22800, accuracy: 100.0, loss: 0.07234571129083633, took 0.021\n",
      "step: 22900, accuracy: 100.0, loss: 0.004808137193322182, took 0.021\n",
      "step: 23000, accuracy: 100.0, loss: 0.004498423542827368, took 0.021\n",
      "step: 23100, accuracy: 100.0, loss: 0.0009604450315237045, took 0.021\n",
      "step: 23200, accuracy: 100.0, loss: 0.011663404293358326, took 0.021\n",
      "step: 23300, accuracy: 75.0, loss: 0.3642735481262207, took 0.021\n",
      "step: 23400, accuracy: 100.0, loss: 0.028590340167284012, took 0.021\n",
      "step: 23500, accuracy: 100.0, loss: 4.672668728744611e-05, took 0.021\n",
      "step: 23600, accuracy: 100.0, loss: 0.0023877727799117565, took 0.021\n",
      "step: 23700, accuracy: 100.0, loss: 0.0021705757826566696, took 0.021\n",
      "step: 23800, accuracy: 100.0, loss: 0.0024315044283866882, took 0.021\n",
      "step: 23900, accuracy: 87.5, loss: 0.19979071617126465, took 0.021\n",
      "step: 24000, accuracy: 100.0, loss: 0.03672031685709953, took 0.021\n",
      "step: 24100, accuracy: 87.5, loss: 0.17570871114730835, took 0.021\n",
      "step: 24200, accuracy: 100.0, loss: 7.863588689360768e-05, took 0.022\n",
      "step: 24300, accuracy: 100.0, loss: 0.007676196284592152, took 0.021\n",
      "step: 24400, accuracy: 100.0, loss: 0.06537823379039764, took 0.021\n",
      "step: 24500, accuracy: 100.0, loss: 0.004756808280944824, took 0.021\n",
      "step: 24600, accuracy: 100.0, loss: 0.021590717136859894, took 0.021\n",
      "step: 24700, accuracy: 100.0, loss: 0.02513320930302143, took 0.021\n",
      "step: 24800, accuracy: 100.0, loss: 0.0037353478837758303, took 0.021\n",
      "step: 24900, accuracy: 100.0, loss: 0.006213068496435881, took 0.021\n",
      "step: 25000, accuracy: 100.0, loss: 0.002181061077862978, took 0.021\n",
      "step: 25100, accuracy: 100.0, loss: 0.032682277262210846, took 0.021\n",
      "step: 25200, accuracy: 100.0, loss: 0.0030428776517510414, took 0.021\n",
      "step: 25300, accuracy: 100.0, loss: 0.002612324198707938, took 0.021\n",
      "step: 25400, accuracy: 100.0, loss: 0.010887924581766129, took 0.021\n",
      "step: 25500, accuracy: 87.5, loss: 0.14866995811462402, took 0.021\n",
      "step: 25600, accuracy: 87.5, loss: 0.3913505971431732, took 0.021\n",
      "step: 25700, accuracy: 87.5, loss: 0.2437296211719513, took 0.021\n",
      "step: 25800, accuracy: 100.0, loss: 0.004428516607731581, took 0.021\n",
      "step: 25900, accuracy: 100.0, loss: 0.011793394573032856, took 0.021\n",
      "step: 26000, accuracy: 100.0, loss: 0.0015553947305306792, took 0.021\n",
      "step: 26100, accuracy: 100.0, loss: 0.0528748594224453, took 0.021\n",
      "step: 26200, accuracy: 87.5, loss: 0.15938900411128998, took 0.021\n",
      "step: 26300, accuracy: 100.0, loss: 0.06609264016151428, took 0.021\n",
      "step: 26400, accuracy: 100.0, loss: 0.0063529247418046, took 0.021\n",
      "step: 26500, accuracy: 100.0, loss: 0.00021104478219058365, took 0.021\n",
      "step: 26600, accuracy: 100.0, loss: 9.119967580772936e-05, took 0.021\n",
      "step: 26700, accuracy: 100.0, loss: 0.005438059102743864, took 0.021\n",
      "step: 26800, accuracy: 100.0, loss: 0.0001431681594112888, took 0.021\n",
      "step: 26900, accuracy: 100.0, loss: 0.005119816865772009, took 0.021\n",
      "step: 27000, accuracy: 100.0, loss: 0.00817791186273098, took 0.021\n",
      "step: 27100, accuracy: 100.0, loss: 0.04066047817468643, took 0.021\n",
      "step: 27200, accuracy: 100.0, loss: 0.0026994540821760893, took 0.021\n",
      "step: 27300, accuracy: 100.0, loss: 0.022317970171570778, took 0.021\n",
      "step: 27400, accuracy: 100.0, loss: 0.009723175317049026, took 0.021\n",
      "step: 27500, accuracy: 100.0, loss: 0.0059173861518502235, took 0.021\n",
      "step: 27600, accuracy: 100.0, loss: 0.005542126018553972, took 0.021\n",
      "step: 27700, accuracy: 100.0, loss: 0.005623574834316969, took 0.021\n",
      "step: 27800, accuracy: 87.5, loss: 0.2964339256286621, took 0.021\n",
      "step: 27900, accuracy: 100.0, loss: 0.002357995603233576, took 0.021\n",
      "step: 28000, accuracy: 100.0, loss: 0.00921015813946724, took 0.021\n",
      "step: 28100, accuracy: 100.0, loss: 0.016473619267344475, took 0.021\n",
      "step: 28200, accuracy: 100.0, loss: 0.007646478712558746, took 0.021\n",
      "step: 28300, accuracy: 100.0, loss: 0.00062755640828982, took 0.021\n",
      "step: 28400, accuracy: 100.0, loss: 0.0013656633673235774, took 0.021\n",
      "step: 28500, accuracy: 100.0, loss: 0.0017003114335238934, took 0.021\n",
      "step: 28600, accuracy: 100.0, loss: 0.08983904123306274, took 0.021\n",
      "step: 28700, accuracy: 100.0, loss: 0.0004962574457749724, took 0.021\n",
      "step: 28800, accuracy: 100.0, loss: 0.01308338064700365, took 0.021\n",
      "step: 28900, accuracy: 100.0, loss: 0.001113835140131414, took 0.021\n",
      "step: 29000, accuracy: 100.0, loss: 0.030501849949359894, took 0.021\n",
      "step: 29100, accuracy: 87.5, loss: 0.1071411594748497, took 0.021\n",
      "step: 29200, accuracy: 100.0, loss: 0.039839569479227066, took 0.021\n",
      "step: 29300, accuracy: 100.0, loss: 0.004392978735268116, took 0.021\n",
      "step: 29400, accuracy: 100.0, loss: 0.0021643834188580513, took 0.021\n",
      "step: 29500, accuracy: 100.0, loss: 0.0009424276649951935, took 0.021\n",
      "step: 29600, accuracy: 100.0, loss: 0.0018212825525552034, took 0.021\n",
      "step: 29700, accuracy: 87.5, loss: 0.11550658941268921, took 0.021\n",
      "step: 29800, accuracy: 100.0, loss: 0.0033517435658723116, took 0.021\n",
      "step: 29900, accuracy: 100.0, loss: 0.002358298283070326, took 0.021\n",
      "step: 30000, accuracy: 100.0, loss: 0.08614019304513931, took 0.021\n",
      "step: 30100, accuracy: 87.5, loss: 0.16234320402145386, took 0.021\n",
      "step: 30200, accuracy: 87.5, loss: 0.16493366658687592, took 0.021\n",
      "step: 30300, accuracy: 100.0, loss: 0.003521620063111186, took 0.021\n",
      "step: 30400, accuracy: 100.0, loss: 0.03918977826833725, took 0.021\n",
      "step: 30500, accuracy: 100.0, loss: 0.002496559638530016, took 0.021\n",
      "step: 30600, accuracy: 100.0, loss: 0.003101322567090392, took 0.021\n",
      "step: 30700, accuracy: 87.5, loss: 0.23120690882205963, took 0.021\n",
      "step: 30800, accuracy: 100.0, loss: 0.019275475293397903, took 0.021\n",
      "step: 30900, accuracy: 87.5, loss: 0.1068887934088707, took 0.023\n",
      "step: 31000, accuracy: 100.0, loss: 0.0011825880501419306, took 0.021\n",
      "step: 31100, accuracy: 100.0, loss: 0.040782127529382706, took 0.021\n",
      "step: 31200, accuracy: 100.0, loss: 0.00012744739069603384, took 0.021\n",
      "step: 31300, accuracy: 100.0, loss: 0.008026150055229664, took 0.021\n",
      "step: 31400, accuracy: 100.0, loss: 0.005087548401206732, took 0.021\n",
      "step: 31500, accuracy: 100.0, loss: 0.004597489256411791, took 0.021\n",
      "step: 31600, accuracy: 100.0, loss: 0.03243451565504074, took 0.021\n",
      "step: 31700, accuracy: 100.0, loss: 0.011396174319088459, took 0.021\n",
      "step: 31800, accuracy: 87.5, loss: 0.5347784757614136, took 0.021\n",
      "step: 31900, accuracy: 100.0, loss: 0.0009556463919579983, took 0.021\n",
      "step: 32000, accuracy: 100.0, loss: 0.01298473123461008, took 0.021\n",
      "step: 32100, accuracy: 100.0, loss: 0.11092475056648254, took 0.021\n",
      "step: 32200, accuracy: 100.0, loss: 0.027083970606327057, took 0.021\n",
      "step: 32300, accuracy: 100.0, loss: 0.027610911056399345, took 0.021\n",
      "step: 32400, accuracy: 100.0, loss: 0.02079879865050316, took 0.021\n",
      "step: 32500, accuracy: 100.0, loss: 0.0010565234115347266, took 0.021\n",
      "step: 32600, accuracy: 100.0, loss: 0.01564938947558403, took 0.021\n",
      "step: 32700, accuracy: 100.0, loss: 0.0007002790807746351, took 0.021\n",
      "step: 32800, accuracy: 87.5, loss: 0.812274158000946, took 0.021\n",
      "step: 32900, accuracy: 100.0, loss: 0.001509460504166782, took 0.021\n",
      "step: 33000, accuracy: 100.0, loss: 0.02566845342516899, took 0.021\n",
      "step: 33100, accuracy: 100.0, loss: 0.0201003085821867, took 0.021\n",
      "step: 33200, accuracy: 100.0, loss: 0.01197774801403284, took 0.021\n",
      "step: 33300, accuracy: 87.5, loss: 0.1901020109653473, took 0.021\n",
      "step: 33400, accuracy: 100.0, loss: 0.013857987709343433, took 0.021\n",
      "step: 33500, accuracy: 100.0, loss: 0.006094730459153652, took 0.021\n",
      "step: 33600, accuracy: 100.0, loss: 0.00031714694341644645, took 0.021\n",
      "step: 33700, accuracy: 87.5, loss: 0.21138490736484528, took 0.021\n",
      "step: 33800, accuracy: 87.5, loss: 0.49232178926467896, took 0.021\n",
      "step: 33900, accuracy: 100.0, loss: 0.03598269447684288, took 0.021\n",
      "step: 34000, accuracy: 100.0, loss: 0.0001996962819248438, took 0.021\n",
      "step: 34100, accuracy: 100.0, loss: 0.08520739525556564, took 0.021\n",
      "step: 34200, accuracy: 100.0, loss: 0.007545545231550932, took 0.021\n",
      "step: 34300, accuracy: 87.5, loss: 0.18418802320957184, took 0.021\n",
      "step: 34400, accuracy: 100.0, loss: 0.2055795043706894, took 0.021\n",
      "step: 34500, accuracy: 100.0, loss: 0.0035255500115454197, took 0.021\n",
      "step: 34600, accuracy: 100.0, loss: 0.00992115493863821, took 0.021\n",
      "step: 34700, accuracy: 100.0, loss: 0.008595380932092667, took 0.021\n",
      "step: 34800, accuracy: 100.0, loss: 0.009091452695429325, took 0.021\n",
      "step: 34900, accuracy: 100.0, loss: 0.0279435645788908, took 0.021\n",
      "step: 35000, accuracy: 100.0, loss: 0.03359650447964668, took 0.021\n",
      "step: 35100, accuracy: 100.0, loss: 0.026495682075619698, took 0.021\n",
      "step: 35200, accuracy: 100.0, loss: 0.002054875250905752, took 0.021\n",
      "step: 35300, accuracy: 100.0, loss: 0.05596990883350372, took 0.021\n",
      "step: 35400, accuracy: 100.0, loss: 0.10095644742250443, took 0.021\n",
      "step: 35500, accuracy: 87.5, loss: 0.3956417143344879, took 0.021\n",
      "step: 35600, accuracy: 100.0, loss: 0.00950572919100523, took 0.021\n",
      "step: 35700, accuracy: 100.0, loss: 0.002069476991891861, took 0.021\n",
      "step: 35800, accuracy: 100.0, loss: 0.00812535546720028, took 0.021\n",
      "step: 35900, accuracy: 100.0, loss: 0.002324963454157114, took 0.021\n",
      "step: 36000, accuracy: 100.0, loss: 0.022614814341068268, took 0.021\n",
      "step: 36100, accuracy: 100.0, loss: 0.0012637142790481448, took 0.021\n",
      "step: 36200, accuracy: 100.0, loss: 0.006937703583389521, took 0.021\n",
      "step: 36300, accuracy: 100.0, loss: 0.009581335820257664, took 0.021\n",
      "step: 36400, accuracy: 87.5, loss: 0.13672785460948944, took 0.021\n",
      "step: 36500, accuracy: 100.0, loss: 0.004856139421463013, took 0.021\n",
      "step: 36600, accuracy: 100.0, loss: 0.00018974696286022663, took 0.021\n",
      "step: 36700, accuracy: 100.0, loss: 0.00032294256379827857, took 0.021\n",
      "step: 36800, accuracy: 100.0, loss: 0.016747698187828064, took 0.021\n",
      "step: 36900, accuracy: 100.0, loss: 0.005820316728204489, took 0.021\n",
      "step: 37000, accuracy: 100.0, loss: 0.005154439248144627, took 0.021\n",
      "step: 37100, accuracy: 100.0, loss: 0.013972990214824677, took 0.021\n",
      "step: 37200, accuracy: 100.0, loss: 0.012725583277642727, took 0.021\n",
      "step: 37300, accuracy: 100.0, loss: 0.011440526694059372, took 0.021\n",
      "step: 37400, accuracy: 100.0, loss: 0.0002576711412984878, took 0.021\n",
      "step: 37500, accuracy: 100.0, loss: 0.0022654100321233273, took 0.021\n",
      "step: 37600, accuracy: 87.5, loss: 1.026100516319275, took 0.021\n",
      "step: 37700, accuracy: 100.0, loss: 0.0031643537804484367, took 0.021\n",
      "step: 37800, accuracy: 100.0, loss: 0.0007714550592936575, took 0.021\n",
      "step: 37900, accuracy: 87.5, loss: 0.521105945110321, took 0.021\n",
      "step: 38000, accuracy: 100.0, loss: 0.0006355023942887783, took 0.021\n",
      "step: 38100, accuracy: 100.0, loss: 0.003387653734534979, took 0.021\n",
      "step: 38200, accuracy: 87.5, loss: 0.1001717820763588, took 0.021\n",
      "step: 38300, accuracy: 100.0, loss: 0.021842367947101593, took 0.021\n",
      "step: 38400, accuracy: 100.0, loss: 0.0040251160971820354, took 0.021\n",
      "step: 38500, accuracy: 100.0, loss: 0.0008136626565828919, took 0.021\n",
      "step: 38600, accuracy: 100.0, loss: 0.00038208180922083557, took 0.021\n",
      "step: 38700, accuracy: 100.0, loss: 0.06960023939609528, took 0.021\n",
      "step: 38800, accuracy: 100.0, loss: 0.0016138860955834389, took 0.021\n",
      "step: 38900, accuracy: 100.0, loss: 0.00018167546659242362, took 0.022\n",
      "step: 39000, accuracy: 100.0, loss: 0.04138898476958275, took 0.021\n",
      "step: 39100, accuracy: 100.0, loss: 0.0013790637021884322, took 0.021\n",
      "step: 39200, accuracy: 100.0, loss: 0.004650888964533806, took 0.021\n",
      "step: 39300, accuracy: 100.0, loss: 0.013843388296663761, took 0.021\n",
      "step: 39400, accuracy: 100.0, loss: 0.030651668086647987, took 0.021\n",
      "step: 39500, accuracy: 100.0, loss: 0.012008963152766228, took 0.021\n",
      "step: 39600, accuracy: 100.0, loss: 0.0011038300581276417, took 0.021\n",
      "step: 39700, accuracy: 100.0, loss: 0.0008726695668883622, took 0.021\n",
      "step: 39800, accuracy: 100.0, loss: 0.04703407734632492, took 0.021\n",
      "step: 39900, accuracy: 100.0, loss: 0.0032726353965699673, took 0.021\n",
      "step: 40000, accuracy: 100.0, loss: 0.00043498293962329626, took 0.021\n",
      "step: 40100, accuracy: 100.0, loss: 0.0006383692962117493, took 0.021\n",
      "step: 40200, accuracy: 100.0, loss: 0.05995752662420273, took 0.021\n",
      "step: 40300, accuracy: 100.0, loss: 0.007818847894668579, took 0.021\n",
      "step: 40400, accuracy: 100.0, loss: 0.0006164581282064319, took 0.021\n",
      "step: 40500, accuracy: 100.0, loss: 0.007645752746611834, took 0.021\n",
      "step: 40600, accuracy: 87.5, loss: 0.10494259744882584, took 0.021\n",
      "step: 40700, accuracy: 100.0, loss: 0.0005522941937670112, took 0.021\n",
      "step: 40800, accuracy: 100.0, loss: 0.013804152607917786, took 0.021\n",
      "step: 40900, accuracy: 100.0, loss: 0.016536155715584755, took 0.021\n",
      "step: 41000, accuracy: 100.0, loss: 0.005390159785747528, took 0.021\n",
      "step: 41100, accuracy: 100.0, loss: 0.040237441658973694, took 0.021\n",
      "step: 41200, accuracy: 87.5, loss: 0.35577481985092163, took 0.021\n",
      "step: 41300, accuracy: 100.0, loss: 0.0005628907238133252, took 0.021\n",
      "step: 41400, accuracy: 100.0, loss: 0.0031451559625566006, took 0.021\n",
      "step: 41500, accuracy: 100.0, loss: 0.0030016745440661907, took 0.021\n",
      "step: 41600, accuracy: 100.0, loss: 0.0761028602719307, took 0.021\n",
      "step: 41700, accuracy: 100.0, loss: 0.0028148419223725796, took 0.021\n",
      "step: 41800, accuracy: 100.0, loss: 0.0417201854288578, took 0.021\n",
      "step: 41900, accuracy: 100.0, loss: 0.06375876814126968, took 0.021\n",
      "step: 42000, accuracy: 100.0, loss: 0.0035870091523975134, took 0.021\n",
      "step: 42100, accuracy: 100.0, loss: 0.0356818363070488, took 0.021\n",
      "step: 42200, accuracy: 100.0, loss: 0.00935389380902052, took 0.021\n",
      "step: 42300, accuracy: 100.0, loss: 0.003121835645288229, took 0.021\n",
      "step: 42400, accuracy: 100.0, loss: 0.014350606128573418, took 0.021\n",
      "step: 42500, accuracy: 100.0, loss: 0.019862182438373566, took 0.021\n",
      "step: 42600, accuracy: 100.0, loss: 0.09015803039073944, took 0.021\n",
      "step: 42700, accuracy: 100.0, loss: 0.03160586953163147, took 0.021\n",
      "step: 42800, accuracy: 100.0, loss: 0.03657200187444687, took 0.021\n",
      "step: 42900, accuracy: 100.0, loss: 0.004588611423969269, took 0.021\n",
      "step: 43000, accuracy: 100.0, loss: 0.0031489189714193344, took 0.021\n",
      "step: 43100, accuracy: 87.5, loss: 0.11579152941703796, took 0.021\n",
      "step: 43200, accuracy: 100.0, loss: 0.023260880261659622, took 0.021\n",
      "step: 43300, accuracy: 100.0, loss: 6.174229929456487e-05, took 0.021\n",
      "step: 43400, accuracy: 100.0, loss: 0.019181646406650543, took 0.021\n",
      "step: 43500, accuracy: 100.0, loss: 0.005870439112186432, took 0.021\n",
      "step: 43600, accuracy: 100.0, loss: 0.07085514813661575, took 0.021\n",
      "step: 43700, accuracy: 87.5, loss: 0.25385531783103943, took 0.021\n",
      "step: 43800, accuracy: 100.0, loss: 0.01474179606884718, took 0.021\n",
      "step: 43900, accuracy: 100.0, loss: 0.00035637267865240574, took 0.021\n",
      "step: 44000, accuracy: 100.0, loss: 0.003640152979642153, took 0.021\n",
      "step: 44100, accuracy: 100.0, loss: 0.04749644547700882, took 0.021\n",
      "step: 44200, accuracy: 100.0, loss: 0.1443849503993988, took 0.021\n",
      "step: 44300, accuracy: 100.0, loss: 0.010274790227413177, took 0.021\n",
      "step: 44400, accuracy: 100.0, loss: 0.03695794939994812, took 0.021\n",
      "step: 44500, accuracy: 100.0, loss: 0.0003595648449845612, took 0.021\n",
      "step: 44600, accuracy: 100.0, loss: 0.000589258735999465, took 0.021\n",
      "step: 44700, accuracy: 100.0, loss: 0.057663775980472565, took 0.021\n",
      "step: 44800, accuracy: 100.0, loss: 0.003206850728020072, took 0.021\n",
      "step: 44900, accuracy: 100.0, loss: 0.0412045456469059, took 0.021\n",
      "step: 45000, accuracy: 87.5, loss: 0.17333565652370453, took 0.021\n",
      "step: 45100, accuracy: 100.0, loss: 0.04281805083155632, took 0.021\n",
      "step: 45200, accuracy: 100.0, loss: 0.001872908091172576, took 0.021\n",
      "step: 45300, accuracy: 87.5, loss: 0.1713828146457672, took 0.021\n",
      "step: 45400, accuracy: 100.0, loss: 0.0009565541986376047, took 0.021\n",
      "step: 45500, accuracy: 100.0, loss: 0.010842906311154366, took 0.021\n",
      "step: 45600, accuracy: 100.0, loss: 0.0011857958743348718, took 0.021\n",
      "step: 45700, accuracy: 100.0, loss: 0.038828738033771515, took 0.021\n",
      "step: 45800, accuracy: 100.0, loss: 9.446043986827135e-05, took 0.021\n",
      "step: 45900, accuracy: 100.0, loss: 0.11663241684436798, took 0.022\n",
      "step: 46000, accuracy: 100.0, loss: 0.009933408349752426, took 0.021\n",
      "step: 46100, accuracy: 100.0, loss: 0.0003844270249828696, took 0.021\n",
      "step: 46200, accuracy: 100.0, loss: 0.00020927522564306855, took 0.021\n",
      "step: 46300, accuracy: 100.0, loss: 0.014378949999809265, took 0.021\n",
      "step: 46400, accuracy: 100.0, loss: 0.004689650610089302, took 0.021\n",
      "step: 46500, accuracy: 100.0, loss: 0.00046621603542007506, took 0.021\n",
      "step: 46600, accuracy: 75.0, loss: 0.665794849395752, took 0.021\n",
      "step: 46700, accuracy: 100.0, loss: 0.0535050593316555, took 0.021\n",
      "step: 46800, accuracy: 100.0, loss: 0.00489078601822257, took 0.021\n",
      "step: 46900, accuracy: 100.0, loss: 0.003863426623865962, took 0.021\n",
      "step: 47000, accuracy: 100.0, loss: 0.002285547321662307, took 0.021\n",
      "step: 47100, accuracy: 100.0, loss: 0.01680121198296547, took 0.021\n",
      "step: 47200, accuracy: 100.0, loss: 0.0071496907621622086, took 0.021\n",
      "step: 47300, accuracy: 100.0, loss: 0.00011405562690924853, took 0.021\n",
      "step: 47400, accuracy: 100.0, loss: 0.00311276875436306, took 0.021\n",
      "step: 47500, accuracy: 100.0, loss: 0.0012312670005485415, took 0.021\n",
      "step: 47600, accuracy: 87.5, loss: 0.19024305045604706, took 0.021\n",
      "step: 47700, accuracy: 100.0, loss: 0.023461846634745598, took 0.021\n",
      "step: 47800, accuracy: 100.0, loss: 0.0003650595899671316, took 0.021\n",
      "step: 47900, accuracy: 100.0, loss: 0.04962274432182312, took 0.021\n",
      "step: 48000, accuracy: 100.0, loss: 0.0035557851660996675, took 0.021\n",
      "step: 48100, accuracy: 100.0, loss: 0.09686961770057678, took 0.021\n",
      "step: 48200, accuracy: 100.0, loss: 0.04539722949266434, took 0.021\n",
      "step: 48300, accuracy: 100.0, loss: 0.0639430433511734, took 0.021\n",
      "step: 48400, accuracy: 100.0, loss: 0.0003823579172603786, took 0.021\n",
      "step: 48500, accuracy: 100.0, loss: 0.02346227504312992, took 0.021\n",
      "step: 48600, accuracy: 87.5, loss: 0.3678221106529236, took 0.021\n",
      "step: 48700, accuracy: 100.0, loss: 0.0018063923344016075, took 0.021\n",
      "step: 48800, accuracy: 100.0, loss: 0.07420127838850021, took 0.021\n",
      "step: 48900, accuracy: 100.0, loss: 0.0021228319965302944, took 0.021\n",
      "step: 49000, accuracy: 100.0, loss: 0.0013158664805814624, took 0.021\n",
      "step: 49100, accuracy: 100.0, loss: 0.0098591772839427, took 0.021\n",
      "step: 49200, accuracy: 100.0, loss: 0.09184795618057251, took 0.021\n",
      "step: 49300, accuracy: 100.0, loss: 0.0032574073411524296, took 0.021\n",
      "step: 49400, accuracy: 100.0, loss: 0.006398424506187439, took 0.021\n",
      "step: 49500, accuracy: 100.0, loss: 0.08085403591394424, took 0.021\n",
      "step: 49600, accuracy: 87.5, loss: 0.4314921200275421, took 0.021\n",
      "step: 49700, accuracy: 100.0, loss: 0.015583637170493603, took 0.021\n",
      "step: 49800, accuracy: 100.0, loss: 0.0051600513979792595, took 0.021\n",
      "step: 49900, accuracy: 100.0, loss: 0.0006403373554348946, took 0.021\n",
      "step: 50000, accuracy: 100.0, loss: 0.00023136415984481573, took 0.021\n",
      "step: 50100, accuracy: 100.0, loss: 0.010004166513681412, took 0.021\n",
      "step: 50200, accuracy: 100.0, loss: 0.000760225229896605, took 0.021\n",
      "step: 50300, accuracy: 87.5, loss: 0.9302278757095337, took 0.022\n",
      "step: 50400, accuracy: 100.0, loss: 0.10828381031751633, took 0.021\n",
      "step: 50500, accuracy: 87.5, loss: 0.6423295736312866, took 0.021\n",
      "step: 50600, accuracy: 100.0, loss: 0.0012129393871873617, took 0.021\n",
      "step: 50700, accuracy: 100.0, loss: 0.001610688166692853, took 0.021\n",
      "step: 50800, accuracy: 100.0, loss: 0.021780842915177345, took 0.021\n",
      "step: 50900, accuracy: 87.5, loss: 0.11956433206796646, took 0.021\n",
      "step: 51000, accuracy: 100.0, loss: 0.0013685416197404265, took 0.021\n",
      "step: 51100, accuracy: 100.0, loss: 0.00013143994146957994, took 0.021\n",
      "step: 51200, accuracy: 100.0, loss: 0.00021120483870618045, took 0.021\n",
      "step: 51300, accuracy: 87.5, loss: 0.14264942705631256, took 0.021\n",
      "step: 51400, accuracy: 100.0, loss: 0.0003440346918068826, took 0.021\n",
      "step: 51500, accuracy: 87.5, loss: 0.1513718217611313, took 0.021\n",
      "step: 51600, accuracy: 100.0, loss: 0.004313179291784763, took 0.021\n",
      "step: 51700, accuracy: 100.0, loss: 0.0003115758881904185, took 0.021\n",
      "step: 51800, accuracy: 100.0, loss: 0.10555395483970642, took 0.021\n",
      "step: 51900, accuracy: 100.0, loss: 0.01726507395505905, took 0.021\n",
      "step: 52000, accuracy: 100.0, loss: 0.0040875570848584175, took 0.021\n",
      "step: 52100, accuracy: 75.0, loss: 0.47741276025772095, took 0.021\n",
      "step: 52200, accuracy: 100.0, loss: 0.011286331340670586, took 0.021\n",
      "step: 52300, accuracy: 87.5, loss: 0.45038241147994995, took 0.021\n",
      "step: 52400, accuracy: 75.0, loss: 1.0058298110961914, took 0.021\n"
     ]
    }
   ],
   "source": [
    "steps = train_size//batch_size * 10\n",
    "print(steps)\n",
    "ans = []\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    for i in range(steps):\n",
    "        t = time.time()\n",
    "        offset = (i * batch_size) % (train_size - batch_size)\n",
    "        batch_data = X[offset:(offset + batch_size), :]\n",
    "        batch_labels = y_oh[offset:(offset + batch_size), :]\n",
    "        feed_dict = {\n",
    "            tf_train_dataset : batch_data.reshape((-1, 28, 28, 1)), \n",
    "            tf_train_labels : batch_labels\n",
    "        }\n",
    "\n",
    "        _, l, pred = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (i < 100 and i % 10 == 0) or i % 100 == 0:\n",
    "            print( \"step: {}, accuracy: {}, loss: {}, took {:.03f}\".format(i, accuracy(pred,batch_labels ), l, time.time()-t))\n",
    "    ans = test_prediction.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = np.argmax(ans, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('answer.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    writer.writerow([\"ImageId\",\"Label\"])\n",
    "    for i, a in enumerate(ans):\n",
    "        writer.writerow([i+1,a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
