{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym as kagglegym\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNetCV, LinearRegression, SGDRegressor, Ridge\n",
    "from sklearn import decomposition\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'timestamp', 'derived_0', 'derived_1', 'derived_2', 'derived_3',\n",
      "       'derived_4', 'fundamental_0', 'fundamental_1', 'fundamental_2',\n",
      "       ...\n",
      "       'technical_36', 'technical_37', 'technical_38', 'technical_39',\n",
      "       'technical_40', 'technical_41', 'technical_42', 'technical_43',\n",
      "       'technical_44', 'y'],\n",
      "      dtype='object', length=111)\n",
      "   id  timestamp\n",
      "0  10          0\n",
      "1  11          0\n",
      "2  12          0\n",
      "3  25          0\n",
      "4  26          0\n",
      "Train has 1710756 rows\n",
      "Target column names: \"id\", \"timestamp\"\n"
     ]
    }
   ],
   "source": [
    "class Target(object):\n",
    "    columns = [\"id\", \"timestamp\"]\n",
    "class Observation(object):\n",
    "    target = Target()\n",
    "    train = None\n",
    "    \n",
    "observation = Observation()\n",
    "with pd.HDFStore(\"./train.h5\", \"r\") as train:\n",
    "    \n",
    "    observation.train = train.get(\"train\")\n",
    "    print(observation.train.columns)\n",
    "    \n",
    "# The \"environment\" is our interface for code competitions\n",
    "# env = kagglegym.make('CartPole-v0')\n",
    "\n",
    "# # We get our initial observation by calling \"reset\"\n",
    "# observation = env.reset()\n",
    "# print(observation)\n",
    "print(observation.train[observation.target.columns].head())\n",
    "# # Note that the first observation we get has a \"train\" dataframe\n",
    "print(\"Train has {} rows\".format(len(observation.train)))\n",
    "\n",
    "# # The \"target\" dataframe is a template for what we need to predict:\n",
    "print(\"Target column names: {}\".format(\", \".join(['\"{}\"'.format(col) for col in list(observation.target.columns)])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = list(observation.train.columns)\n",
    "cols.remove('id')\n",
    "cols.remove('timestamp')\n",
    "cols.remove('y')\n",
    "\n",
    "mean_values = observation.train[cols].mean(axis=0)\n",
    "xStd = observation.train[cols].std(axis=0)  # Remember to save this value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in cols:\n",
    "    observation.train[c].fillna(mean_values[c], inplace=True)\n",
    "    observation.train[c] = np.tanh((observation.train[c] - mean_values[c])/xStd[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observation.train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(observation.train.copy(), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1146206, 111), (564550, 111))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.093497805297374725, -0.086094126105308533)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = dict(observation.train.y.describe())\n",
    "\n",
    "cut_max = 0.093\n",
    "cut_min = -0.086\n",
    "(desc[\"max\"], desc[\"min\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median_group = dict(observation.train.groupby([\"id\"])[\"y\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#median_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(observation.train.y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weighted_y(series):\n",
    "    id, y = series[\"id\"], series[\"y\"]\n",
    "    return 0.95 * y + 0.05 * median_group[id] if id in median_group else y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_cols_to_use = ['technical_30', 'technical_20', 'fundamental_11'] + ['technical_19', 'technical_36'] \n",
    "y_is_above_cut = (train.y > cut_max)\n",
    "y_is_below_cut = (train.y < cut_min)\n",
    "y_is_within_cut = (~y_is_above_cut & ~y_is_below_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(train.loc[y_is_within_cut, ridge_cols_to_use].values)\n",
    "y = train.loc[y_is_within_cut, \"y\"]\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_poly = poly.fit_transform(np.array(train.loc[y_is_within_cut, ridge_cols_to_use].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ridge()\n",
    "model.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_pred_test = test[[\"id\", \"y\"]].copy()\n",
    "X_test = poly.transform(test[ridge_cols_to_use])\n",
    "ridge_pred_test.y = model.predict(X_test).clip(cut_min, cut_max)\n",
    "ridge_pred_test.y = ridge_pred_test.apply(get_weighted_y, axis = 1)\n",
    "test[\"y_ridge\"] = ridge_pred_test.y.astype(np.float32)\n",
    "\n",
    "ridge_pred_train = train[[\"id\", \"y\"]].copy()\n",
    "ridge_pred_train.y = model.predict(poly.transform(train[ridge_cols_to_use])).clip(cut_min, cut_max)\n",
    "ridge_pred_train.y = ridge_pred_train.apply(get_weighted_y, axis = 1)\n",
    "train[\"y_ridge\"] = ridge_pred_train.y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GBoost\n",
    "gb_cols = ridge_cols_to_use + ['y_ridge']\n",
    "X_gb = np.array(train.loc[y_is_within_cut, gb_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=4,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=250, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboptions = {\"verbose\":True, \"max_depth\":4, \"n_estimators\":250, \"subsample\":0.8, \"learning_rate\":0.01}\n",
    "rfoptions = {\"verbose\":True, \"max_depth\":4, \"n_estimators\":250, \"n_jobs\":-1}\n",
    "\n",
    "regression = ensemble.GradientBoostingRegressor(**gboptions)\n",
    "#regression = ensemble.RandomForestRegressor(**rfoptions)\n",
    "regression.fit(X_gb, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 250 out of 250 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "gb_pred_test = test[[\"id\", \"y\"]].copy()\n",
    "gb_pred_test.y = regression.predict(test[gb_cols])\n",
    "gb_pred_test.y = ridge_pred_test.apply(get_weighted_y, axis = 1)\n",
    "#test[\"y_ridge\"] = ridge_pred_test.y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00090052366552484386"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metric\n",
    "metrics.r2_score(test.y.values, gb_pred_test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# metrics.r2_score(test.y.values, gb_pred_test.y)\n",
    "metrics.r2_score(test.y.values, ridge_pred_test.y)\n",
    "# ElasticNetCV - 0.000107 (3)\n",
    "# ElasticNetCV - 0.000109 (5)\n",
    "# Ridge        - 0.000270 (3)\n",
    "# Ridge        - 0.000303 (5)\n",
    "# Ridge        - 0.000727 (5) + poly 3\n",
    "# Ridge        - 0.000823 (5) + poly 4\n",
    "# GBoost       - 0.000912 (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(test)), np.cumsum(ridge_pred_test.y.values))\n",
    "plt.plot(range(len(test)), np.cumsum(test.y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cols = list(train.columns)\n",
    "# cols.remove('id')\n",
    "# cols.remove('timestamp')\n",
    "# cols.remove('y')\n",
    "cols = ridge_cols_to_use + ['y_ridge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gboptions = {\"verbose\":True, \"max_depth\":4, \"n_estimators\":200, \"subsample\":0.8, \"learning_rate\":0.02}\n",
    "\n",
    "regression = ensemble.GradientBoostingRegressor(**gboptions)\n",
    "regression.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.r2_score(test.y.values, gb_pred_test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NN for dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=cols.__len__())]\n",
    "DNN = tf.contrib.learn.DNNRegressor(hidden_units=[200, 100, 40], feature_columns=feature_columns, activation_fn=tf.tanh)\n",
    "DNN.fit(train[cols].values, train[\"y\"].values, steps=50000, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_tf = DNN.predict(test[cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_tf_2  = list(prediction_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.r2_score(test.y.values, prediction_tf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wb(wshape=[None], bshape=[None], device='/cpu:0'):\n",
    "    with tf.device(device):\n",
    "        w = tf.get_variable(\"w\", wshape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b = tf.get_variable('b', bshape, initializer=tf.constant_initializer(0.0))\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "l2_reg_norm = 5e-5\n",
    "features = cols.__len__()\n",
    "train_size = train.shape[0]\n",
    "\n",
    "widest = 64\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X_tf = tf.placeholder(tf.float32, shape=(batch_size, features))\n",
    "    y_tf = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
    "    X_test = tf.constant(test[cols].values)\n",
    "    y_test = tf.constant(test[[\"y\"]].values)\n",
    "\n",
    "    with tf.variable_scope(\"Layer1\"):\n",
    "            layer1_weights, layer1_biases = wb([features, widest], [widest])\n",
    "    with tf.variable_scope(\"Layer2\"):\n",
    "            layer2_weights, layer2_biases = wb([widest, widest], [widest])\n",
    "    with tf.variable_scope(\"Layer3\"):\n",
    "            layer3_weights, layer3_biases = wb([widest, 1], [1])\n",
    "\n",
    "    def model(data, train=True):\n",
    "        print(\"data\", data.get_shape())\n",
    "        \n",
    "        layer1 = tf.nn.relu(tf.matmul(data, layer1_weights) + layer1_biases)\n",
    "        print(\"layer1\", layer1.get_shape())\n",
    "        if train:\n",
    "            layer1 = tf.nn.dropout(layer1, 0.5)\n",
    "        \n",
    "        layer2 = tf.nn.relu(tf.matmul(layer1, layer2_weights) + layer2_biases)\n",
    "        print(\"layer2\", layer2.get_shape())\n",
    "        if train:\n",
    "            layer2 = tf.nn.dropout(layer2, 0.5)\n",
    "            \n",
    "        layer3 = tf.tanh(tf.matmul(layer2, layer3_weights) + layer3_biases)\n",
    "        print(\"layer3\", layer3.get_shape())\n",
    "        \n",
    "        return layer3\n",
    "    \n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        predictions = model(X_tf)\n",
    "        regularizers = (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer1_biases) + \n",
    "                        tf.nn.l2_loss(layer2_weights) + tf.nn.l2_loss(layer2_biases) + \n",
    "                        tf.nn.l2_loss(layer3_weights) + tf.nn.l2_loss(layer3_biases))\n",
    "        loss_l2 = l2_reg_norm * regularizers\n",
    "        loss_data = tf.reduce_mean(tf.square(predictions - y_tf))\n",
    "        loss = loss_data #+ loss_l2\n",
    "        \n",
    "\n",
    "        # Optimizer.\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learn_rate  = tf.train.exponential_decay(.001, global_step*batch_size, train_size, 0.5, staircase=True)\n",
    "        optimizer = tf.train.AdamOptimizer(learn_rate).minimize(loss, global_step=global_step, name=\"Optimizer\")\n",
    "\n",
    "        #test\n",
    "    \n",
    "        test_prediction = model(X_test, train=False)\n",
    "        loss_test = metrics.r2_score(y_test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = train_size//batch_size * 4\n",
    "print(num_steps)\n",
    "y_vals = train[[\"y\"]].values\n",
    "x_vals = train[cols].values\n",
    "train_preds_nn = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver()\n",
    "    init_op.run()\n",
    "    print(\"Initialized valiables\")\n",
    "    for i in range(num_steps):\n",
    "\n",
    "        offset = (i*batch_size) % (train_size - batch_size)\n",
    "        y_ = y_vals[offset:offset+batch_size, :]\n",
    "        X_ = x_vals[offset:offset+batch_size, :]\n",
    "\n",
    "        feed_dict = {X_tf : X_, y_tf : y_}\n",
    "        _, l, pred = sess.run([optimizer, loss, predictions], feed_dict=feed_dict)\n",
    "        if (i < 1000 and i%100 == 0) or i%10000 == 0:\n",
    "            print(i, l)\n",
    "        if i>0 and i%30000 == 0:\n",
    "            print(i, \"test\", loss_test.eval())\n",
    "#         if i>0 and i%30000 == 0:\n",
    "#             save_path = saver.save(sess, \"ts_{}.ckpt\".format(i))\n",
    "    train_preds_nn = test_prediction.eval()\n",
    "    save_path = saver.save(sess, \"ts_end.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# fig = plt.figure(figsize=(8, 20))\n",
    "# plot_count = 0\n",
    "# for col in cols:\n",
    "#     plot_count += 1\n",
    "#     plt.subplot(cols.__len__(), 1, plot_count)\n",
    "#     plt.scatter(range(train.shape[0]), train[col].values)\n",
    "#     plt.title(\"Distribution of \"+col)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(range(100), test.y.values[:100])\n",
    "plt.plot(range(100), train_preds_nn[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_pred_test.y.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
